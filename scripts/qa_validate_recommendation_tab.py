"""
Recommendation Analysis Tab QA é©—è­‰è…³æœ¬
è‡ªå‹•æª¢æŸ¥èˆ‡æ¸¬è©¦æ¨è–¦åˆ†æåŠŸèƒ½æ˜¯å¦æ­£ç¢ºã€ç©©å®šã€å¯å›æ­¸
"""

import sys
import os
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import traceback
import logging
from typing import List, Dict, Any, Optional

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from data_module.config import TWStockConfig
from app_module.recommendation_service import RecommendationService
from app_module.regime_service import RegimeService
from app_module.dtos import RecommendationDTO, RecommendationResultDTO
# from ui_app.industry_mapper import IndustryMapper
# from ui_app.strategy_configurator import StrategyConfigurator
from decision_module.industry_mapper import IndustryMapper
from decision_module.strategy_configurator import StrategyConfigurator

# ç¢ºä¿ç­–ç•¥å·²è¨»å†Š
import app_module.strategies  # é€™æœƒè§¸ç™¼ç­–ç•¥è¨»å†Š

# è¨­ç½®æ—¥èªŒ
log_dir = project_root / 'output' / 'qa' / 'recommendation_tab'
log_dir.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.DEBUG,  # âœ… æ”¹ç‚º DEBUG ä»¥æŸ¥çœ‹è©³ç´°éç¨‹
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',
    handlers=[
        logging.FileHandler(log_dir / 'RUN_LOG.txt', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# æ¸¬è©¦é…ç½®
TEST_STOCKS = {
    'large_cap': '2330',  # å°ç©é›»ï¼ˆå¤§å‹è‚¡ï¼‰
    'mid_cap': '2317',    # é´»æµ·ï¼ˆä¸­å‹è‚¡ï¼‰
    'volatile': '2454',   # è¯ç™¼ç§‘ï¼ˆæ³¢å‹•è¼ƒå¤§ï¼‰
}

# é æœŸæ¬„ä½ï¼ˆå¾ RecommendationDTO.to_dict() å’Œ UI ä½¿ç”¨ï¼‰
EXPECTED_DTO_FIELDS = {
    'è­‰åˆ¸ä»£è™Ÿ': str,
    'è­‰åˆ¸åç¨±': str,
    'æ”¶ç›¤åƒ¹': float,
    'æ¼²å¹…%': float,
    'ç¸½åˆ†': float,
    'æŒ‡æ¨™åˆ†': float,
    'åœ–å½¢åˆ†': float,
    'æˆäº¤é‡åˆ†': float,
    'æ¨è–¦ç†ç”±': str,
    'ç”¢æ¥­': str,
    'RegimeåŒ¹é…': str,
}

# åˆ†æ•¸ç¯„åœ
SCORE_RANGE = {
    'total_score': (0, 100),
    'indicator_score': (0, 100),
    'pattern_score': (0, 100),
    'volume_score': (0, 100),
}

# NaN å®¹å¿åº¦
MAX_NAN_RATIO = 0.1  # æœ€å¤š 10% çš„æ¬„ä½å¯ä»¥æ˜¯ NaN


class ValidationResult:
    """é©—è­‰çµæœè¨˜éŒ„"""
    def __init__(self):
        self.passed = []
        self.failed = []
        self.skipped = []
        self.evidence = {}
        self.issues = {
            'logic_errors': [],
            'contract_violations': [],
            'data_quality': [],
            'ui_service_mismatch': [],
        }
    
    def add_pass(self, feature, evidence=None):
        self.passed.append(feature)
        if evidence:
            self.evidence[feature] = evidence
    
    def add_fail(self, feature, error, evidence=None, issue_type='logic_errors'):
        self.failed.append({
            'feature': feature,
            'error': error,
            'evidence': evidence,
            'issue_type': issue_type
        })
        if issue_type in self.issues:
            self.issues[issue_type].append({
                'feature': feature,
                'error': error,
                'evidence': evidence
            })
    
    def add_skip(self, feature, reason):
        self.skipped.append({
            'feature': feature,
            'reason': reason
        })


def validate_dto_structure(dto: RecommendationDTO, result: ValidationResult) -> bool:
    """é©—è­‰ DTO çµæ§‹"""
    try:
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_fields = ['stock_code', 'stock_name', 'close_price', 'price_change',
                          'total_score', 'indicator_score', 'pattern_score', 'volume_score',
                          'recommendation_reasons', 'industry', 'regime_match']
        
        missing_fields = []
        for field in required_fields:
            if not hasattr(dto, field):
                missing_fields.append(field)
        
        if missing_fields:
            result.add_fail(
                'DTO_Structure',
                f"DTO ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_fields}",
                issue_type='contract_violations'
            )
            return False
        
        # æª¢æŸ¥ to_dict() è¼¸å‡º
        dto_dict = dto.to_dict()
        for expected_field, expected_type in EXPECTED_DTO_FIELDS.items():
            if expected_field not in dto_dict:
                result.add_fail(
                    'DTO_to_dict',
                    f"to_dict() ç¼ºå°‘æ¬„ä½: {expected_field}",
                    evidence={'available_fields': list(dto_dict.keys())},
                    issue_type='contract_violations'
                )
                return False
            
            # æª¢æŸ¥é¡å‹ï¼ˆå…è¨± Noneï¼‰
            if dto_dict[expected_field] is not None:
                actual_type = type(dto_dict[expected_field])
                if not isinstance(dto_dict[expected_field], expected_type):
                    result.add_fail(
                        'DTO_Type',
                        f"æ¬„ä½ {expected_field} é¡å‹éŒ¯èª¤: æœŸæœ› {expected_type}, å¯¦éš› {actual_type}",
                        evidence={'value': dto_dict[expected_field]},
                        issue_type='contract_violations'
                    )
                    return False
        
        return True
        
    except Exception as e:
        result.add_fail('DTO_Structure', str(e), traceback.format_exc())
        return False


def validate_score_ranges(dto: RecommendationDTO, result: ValidationResult) -> bool:
    """é©—è­‰åˆ†æ•¸ç¯„åœ"""
    try:
        issues = []
        
        # æª¢æŸ¥ç¸½åˆ†
        if not (SCORE_RANGE['total_score'][0] <= dto.total_score <= SCORE_RANGE['total_score'][1]):
            issues.append(f"ç¸½åˆ†è¶…å‡ºç¯„åœ: {dto.total_score} (æ‡‰åœ¨ {SCORE_RANGE['total_score']})")
        
        # æª¢æŸ¥æŒ‡æ¨™åˆ†
        if not (SCORE_RANGE['indicator_score'][0] <= dto.indicator_score <= SCORE_RANGE['indicator_score'][1]):
            issues.append(f"æŒ‡æ¨™åˆ†è¶…å‡ºç¯„åœ: {dto.indicator_score} (æ‡‰åœ¨ {SCORE_RANGE['indicator_score']})")
        
        # æª¢æŸ¥åœ–å½¢åˆ†
        if not (SCORE_RANGE['pattern_score'][0] <= dto.pattern_score <= SCORE_RANGE['pattern_score'][1]):
            issues.append(f"åœ–å½¢åˆ†è¶…å‡ºç¯„åœ: {dto.pattern_score} (æ‡‰åœ¨ {SCORE_RANGE['pattern_score']})")
        
        # æª¢æŸ¥æˆäº¤é‡åˆ†
        if not (SCORE_RANGE['volume_score'][0] <= dto.volume_score <= SCORE_RANGE['volume_score'][1]):
            issues.append(f"æˆäº¤é‡åˆ†è¶…å‡ºç¯„åœ: {dto.volume_score} (æ‡‰åœ¨ {SCORE_RANGE['volume_score']})")
        
        if issues:
            result.add_fail(
                'Score_Range',
                "; ".join(issues),
                evidence={'dto': dto.__dict__},
                issue_type='data_quality'
            )
            return False
        
        return True
        
    except Exception as e:
        result.add_fail('Score_Range', str(e), traceback.format_exc())
        return False


def validate_dataframe_quality(df: pd.DataFrame, result: ValidationResult, test_name: str) -> bool:
    """é©—è­‰ DataFrame å“è³ª"""
    try:
        issues = []
        
        # æª¢æŸ¥ DataFrame æ˜¯å¦ç‚ºç©º
        if len(df) == 0:
            result.add_fail(
                f'{test_name}_EmptyDataFrame',
                "DataFrame ç‚ºç©º",
                issue_type='data_quality'
            )
            return False
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = list(EXPECTED_DTO_FIELDS.keys())
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            result.add_fail(
                f'{test_name}_MissingColumns',
                f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}",
                evidence={'available_columns': list(df.columns)},
                issue_type='contract_violations'
            )
            return False
        
        # æª¢æŸ¥ NaN æ¯”ä¾‹
        for col in df.columns:
            nan_count = df[col].isna().sum()
            nan_ratio = nan_count / len(df)
            if nan_ratio > MAX_NAN_RATIO:
                issues.append(f"æ¬„ä½ {col} NaN æ¯”ä¾‹éé«˜: {nan_ratio:.2%} (>{MAX_NAN_RATIO:.2%})")
        
        # æª¢æŸ¥åˆ†æ•¸æ¬„ä½çš„ NaN
        score_columns = ['ç¸½åˆ†', 'æŒ‡æ¨™åˆ†', 'åœ–å½¢åˆ†', 'æˆäº¤é‡åˆ†']
        for col in score_columns:
            if col in df.columns:
                nan_count = df[col].isna().sum()
                if nan_count > 0:
                    issues.append(f"åˆ†æ•¸æ¬„ä½ {col} æœ‰ {nan_count} å€‹ NaN")
        
        # æª¢æŸ¥æ’åºï¼ˆç¸½åˆ†æ‡‰è©²é™åºï¼‰
        if 'ç¸½åˆ†' in df.columns:
            if not df['ç¸½åˆ†'].is_monotonic_decreasing:
                # å…è¨±å‰å¹¾å€‹ç›¸åŒåˆ†æ•¸
                sorted_df = df.sort_values('ç¸½åˆ†', ascending=False)
                if not df['ç¸½åˆ†'].equals(sorted_df['ç¸½åˆ†']):
                    issues.append("ç¸½åˆ†æœªæŒ‰é™åºæ’åˆ—")
        
        if issues:
            result.add_fail(
                f'{test_name}_DataQuality',
                "; ".join(issues),
                evidence={'shape': df.shape, 'columns': list(df.columns)},
                issue_type='data_quality'
            )
            return False
        
        return True
        
    except Exception as e:
        result.add_fail(f'{test_name}_DataQuality', str(e), traceback.format_exc())
        return False


def validate_service_layer(config, result: ValidationResult):
    """é©—è­‰ Service å±¤ï¼ˆä¸å•Ÿå‹• UIï¼‰"""
    logger.info("=" * 80)
    logger.info("é©—è­‰ Service å±¤")
    logger.info("=" * 80)
    
    try:
        industry_mapper = IndustryMapper(config)
        recommendation_service = RecommendationService(config, industry_mapper)
        regime_service = RegimeService(config)
        
        # ç²å–ç•¶å‰ Regime
        regime_result = regime_service.detect_regime()
        current_regime = regime_result.regime
        logger.info(f"ç•¶å‰å¸‚å ´ç‹€æ…‹: {current_regime} (ä¿¡å¿ƒåº¦: {regime_result.confidence:.2%})")
        
        # æ¸¬è©¦é…ç½®ï¼ˆæ”¾å¯¬ç¯©é¸æ¢ä»¶ä»¥ç¢ºä¿æœ‰çµæœï¼‰
        test_configs = [
            {
                'name': 'åŸºæœ¬é…ç½®ï¼ˆæ”¾å¯¬ç¯©é¸ï¼‰',
                'config': {
                    'technical': {
                        'momentum': {
                            'enabled': True,
                            'rsi': {'enabled': True, 'period': 14},
                            'macd': {'enabled': True, 'fast': 12, 'slow': 26, 'signal': 9},
                            'kd': {'enabled': False}
                        },
                        'volatility': {
                            'enabled': False,
                            'bollinger': {'enabled': False},
                            'atr': {'enabled': True, 'period': 14}
                        },
                        'trend': {
                            'enabled': True,
                            'adx': {'enabled': True, 'period': 14},
                            'ma': {'enabled': True, 'windows': [5, 10, 20, 60]}
                        }
                    },
                    'patterns': {
                        'selected': ['Wåº•']
                    },
                    'signals': {
                        'technical_indicators': ['momentum', 'trend'],
                        'volume_conditions': ['increasing'],
                        'weights': {'pattern': 0.30, 'technical': 0.50, 'volume': 0.20}
                    },
                    'filters': {
                        'price_change_min': -10.0,  # å…è¨±è² å ±é…¬
                        'price_change_max': 100.0,
                        'volume_ratio_min': 0.5,  # é™ä½æˆäº¤é‡è¦æ±‚
                        'industry': 'å…¨éƒ¨'
                    },
                    'regime': current_regime
                }
            },
            {
                'name': 'åƒ…ç§»å‹•å¹³å‡ç·š',
                'config': {
                    'technical': {
                        'momentum': {
                            'enabled': False,
                            'rsi': {'enabled': False},
                            'macd': {'enabled': False},
                            'kd': {'enabled': False}
                        },
                        'volatility': {
                            'enabled': False,
                            'bollinger': {'enabled': False},
                            'atr': {'enabled': True, 'period': 14}
                        },
                        'trend': {
                            'enabled': True,
                            'adx': {'enabled': False},
                            'ma': {'enabled': True, 'windows': [5, 10, 20, 60]}
                        }
                    },
                    'patterns': {
                        'selected': ['Wåº•']
                    },
                    'signals': {
                        'technical_indicators': ['trend'],
                        'volume_conditions': ['increasing'],
                        'weights': {'pattern': 0.30, 'technical': 0.50, 'volume': 0.20}
                    },
                    'filters': {
                        'price_change_min': -10.0,
                        'price_change_max': 100.0,
                        'volume_ratio_min': 0.5,
                        'industry': 'å…¨éƒ¨'
                    },
                    'regime': current_regime
                }
            },
            {
                'name': 'ç”¢æ¥­ç¯©é¸ï¼ˆåŠå°é«”æ¥­ï¼‰',
                'config': {
                    'technical': {
                        'momentum': {
                            'enabled': True,
                            'rsi': {'enabled': True, 'period': 14},
                            'macd': {'enabled': False},
                            'kd': {'enabled': False}
                        },
                        'volatility': {
                            'enabled': False,
                            'bollinger': {'enabled': False},
                            'atr': {'enabled': True, 'period': 14}
                        },
                        'trend': {
                            'enabled': True,
                            'adx': {'enabled': False},
                            'ma': {'enabled': True, 'windows': [5, 10, 20, 60]}
                        }
                    },
                    'patterns': {
                        'selected': ['Wåº•']
                    },
                    'signals': {
                        'technical_indicators': ['momentum', 'trend'],
                        'volume_conditions': ['increasing'],
                        'weights': {'pattern': 0.30, 'technical': 0.50, 'volume': 0.20}
                    },
                    'filters': {
                        'price_change_min': -10.0,
                        'price_change_max': 100.0,
                        'volume_ratio_min': 0.5,
                        'industry': 'åŠå°é«”æ¥­'
                    },
                    'regime': current_regime
                }
            }
        ]
        
        for test_case in test_configs:
            test_name = test_case['name']
            test_config = test_case['config']
            
            logger.info(f"\n[Service Test] {test_name}")
            logger.info(f"  é…ç½®: {json.dumps(test_config, indent=2, ensure_ascii=False)}")
            
            try:
                # åŸ·è¡Œæ¨è–¦åˆ†æ
                recommendations = recommendation_service.run_recommendation(
                    config=test_config,
                    max_stocks=50,
                    top_n=10
                )
                
                logger.info(f"  è¿”å› {len(recommendations)} å€‹æ¨è–¦")
                
                # é©—è­‰è¿”å›é¡å‹
                if not isinstance(recommendations, list):
                    result.add_fail(
                        f'{test_name}_ReturnType',
                        f"è¿”å›é¡å‹éŒ¯èª¤: {type(recommendations)}, æœŸæœ› list",
                        issue_type='contract_violations'
                    )
                    continue
                
                # å¦‚æœæ²’æœ‰çµæœï¼Œè¨˜éŒ„ä½†ä¸ä¸€å®šå¤±æ•—ï¼ˆå¯èƒ½æ˜¯ç¯©é¸æ¢ä»¶å¤ªåš´æ ¼ï¼‰
                if len(recommendations) == 0:
                    logger.warning(f"  âš ï¸ æ²’æœ‰æ‰¾åˆ°æ¨è–¦ï¼ˆå¯èƒ½æ˜¯ç¯©é¸æ¢ä»¶å¤ªåš´æ ¼ï¼‰")
                    result.add_skip(
                        f'{test_name}_NoResults',
                        "æ²’æœ‰æ‰¾åˆ°æ¨è–¦çµæœï¼ˆå¯èƒ½æ˜¯ç¯©é¸æ¢ä»¶å¤ªåš´æ ¼æˆ–æ•¸æ“šå•é¡Œï¼‰"
                    )
                    continue
                
                # é©—è­‰æ¯å€‹ DTO
                for idx, rec in enumerate(recommendations):
                    if not isinstance(rec, RecommendationDTO):
                        result.add_fail(
                            f'{test_name}_DTOType',
                            f"ç¬¬ {idx} å€‹å…ƒç´ é¡å‹éŒ¯èª¤: {type(rec)}, æœŸæœ› RecommendationDTO",
                            issue_type='contract_violations'
                        )
                        break
                    
                    # é©—è­‰ DTO çµæ§‹
                    if not validate_dto_structure(rec, result):
                        break
                    
                    # é©—è­‰åˆ†æ•¸ç¯„åœ
                    if not validate_score_ranges(rec, result):
                        break
                
                # è½‰æ›ç‚º DataFrame ä¸¦é©—è­‰
                if len(recommendations) > 0:
                    data = [rec.to_dict() for rec in recommendations]
                    df = pd.DataFrame(data)
                    
                    # ä¿å­˜è­‰æ“š
                    evidence_file = log_dir / f'{test_name.replace(" ", "_")}_results.csv'
                    df.to_csv(evidence_file, index=False, encoding='utf-8-sig')
                    
                    # é©—è­‰ DataFrame å“è³ª
                    if validate_dataframe_quality(df, result, test_name):
                        result.add_pass(f'{test_name}_Service', {
                            'file': str(evidence_file),
                            'count': len(recommendations),
                            'columns': list(df.columns),
                            'shape': df.shape
                        })
                    
                    # è¨˜éŒ„çµ±è¨ˆä¿¡æ¯
                    logger.info(f"  DataFrame shape: {df.shape}")
                    logger.info(f"  DataFrame columns: {list(df.columns)}")
                    if 'ç¸½åˆ†' in df.columns:
                        logger.info(f"  ç¸½åˆ†ç¯„åœ: {df['ç¸½åˆ†'].min():.2f} ~ {df['ç¸½åˆ†'].max():.2f}")
                        logger.info(f"  ç¸½åˆ†å¹³å‡: {df['ç¸½åˆ†'].mean():.2f}")
                    
            except Exception as e:
                result.add_fail(
                    f'{test_name}_Exception',
                    str(e),
                    traceback.format_exc(),
                    issue_type='logic_errors'
                )
        
    except Exception as e:
        logger.error(f"Service å±¤é©—è­‰å¤±æ•—: {e}")
        logger.error(traceback.format_exc())
        result.add_fail('Service_Layer_Setup', str(e), traceback.format_exc())


def validate_ui_service_contract(result: ValidationResult):
    """é©—è­‰ UI èˆ‡ Service çš„ Contract"""
    logger.info("=" * 80)
    logger.info("é©—è­‰ UI â†” Service Contract")
    logger.info("=" * 80)
    
    try:
        # è®€å– UI ä»£ç¢¼ï¼Œæª¢æŸ¥ä½¿ç”¨çš„æ¬„ä½
        ui_file = project_root / 'ui_qt' / 'views' / 'recommendation_view.py'
        if not ui_file.exists():
            result.add_skip('UI_Contract_Check', "æ‰¾ä¸åˆ° UI æ–‡ä»¶")
            return
        
        ui_code = ui_file.read_text(encoding='utf-8')
        
        # æª¢æŸ¥ UI ä¸­ä½¿ç”¨çš„æ¬„ä½ï¼ˆå¾ to_dict() è½‰æ›å¾Œçš„æ¬„ä½åï¼‰
        # UI ä½¿ç”¨ rec.to_dict() è½‰æ›ç‚º DataFrameï¼Œæ‰€ä»¥æ‡‰è©²ä½¿ç”¨ DTO.to_dict() çš„æ¬„ä½å
        ui_used_fields = []
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ç›´æ¥è¨ªå• DTO å±¬æ€§çš„åœ°æ–¹
        # å¯¦éš›ä¸Š UI ä½¿ç”¨ to_dict()ï¼Œæ‰€ä»¥æ‡‰è©²æª¢æŸ¥ to_dict() çš„è¼¸å‡ºæ¬„ä½
        
        # é©—è­‰æ‰€æœ‰ EXPECTED_DTO_FIELDS éƒ½å­˜åœ¨æ–¼ DTO.to_dict() ä¸­
        from app_module.dtos import RecommendationDTO
        
        # å‰µå»ºä¸€å€‹æ¸¬è©¦ DTO ä¾†æª¢æŸ¥ to_dict() è¼¸å‡º
        test_dto = RecommendationDTO(
            stock_code='TEST',
            stock_name='æ¸¬è©¦',
            close_price=100.0,
            price_change=1.0,
            total_score=50.0,
            indicator_score=50.0,
            pattern_score=50.0,
            volume_score=50.0,
            recommendation_reasons='æ¸¬è©¦ç†ç”±',
            industry='æ¸¬è©¦ç”¢æ¥­',
            regime_match=True
        )
        
        test_dict = test_dto.to_dict()
        
        # æª¢æŸ¥æ‰€æœ‰é æœŸæ¬„ä½éƒ½å­˜åœ¨
        missing_in_dto = []
        for field in EXPECTED_DTO_FIELDS.keys():
            if field not in test_dict:
                missing_in_dto.append(field)
        
        if missing_in_dto:
            result.add_fail(
                'UI_Contract_DTO_MissingFields',
                f"DTO.to_dict() ç¼ºå°‘ UI éœ€è¦çš„æ¬„ä½: {missing_in_dto}",
                evidence={'dto_fields': list(test_dict.keys())},
                issue_type='contract_violations'
            )
        else:
            result.add_pass('UI_Contract_DTO', {
                'dto_fields': list(test_dict.keys()),
                'expected_fields': list(EXPECTED_DTO_FIELDS.keys())
            })
        
        # æª¢æŸ¥ UI é è¨­é…ç½®èˆ‡ Service é è¨­é…ç½®çš„ä¸€è‡´æ€§
        # é€™éœ€è¦æ‰‹å‹•æª¢æŸ¥ï¼Œå› ç‚º UI å’Œ Service çš„é è¨­é…ç½®å¯èƒ½ä¸åŒ
        
    except Exception as e:
        logger.error(f"UI Contract é©—è­‰å¤±æ•—: {e}")
        logger.error(traceback.format_exc())
        result.add_fail('UI_Contract_Check', str(e), traceback.format_exc())


def validate_filtering_logic(config, result: ValidationResult):
    """é©—è­‰ç¯©é¸é‚è¼¯"""
    logger.info("=" * 80)
    logger.info("é©—è­‰ç¯©é¸é‚è¼¯")
    logger.info("=" * 80)
    
    try:
        industry_mapper = IndustryMapper(config)
        recommendation_service = RecommendationService(config, industry_mapper)
        regime_service = RegimeService(config)
        
        regime_result = regime_service.detect_regime()
        current_regime = regime_result.regime
        
        # æ¸¬è©¦ä¸åŒçš„ç¯©é¸æ¢ä»¶
        filter_tests = [
            {
                'name': 'ç„¡ç¯©é¸æ¢ä»¶',
                'filters': {
                    'price_change_min': -100.0,  # æ¥µå¯¬é¬†
                    'price_change_max': 100.0,
                    'volume_ratio_min': 0.0,  # æ¥µå¯¬é¬†
                    'industry': 'å…¨éƒ¨'
                }
            },
            {
                'name': 'åš´æ ¼æ¼²å¹…ç¯©é¸',
                'filters': {
                    'price_change_min': 5.0,  # è¦æ±‚æ¼²å¹… >= 5%
                    'price_change_max': 100.0,
                    'volume_ratio_min': 0.0,
                    'industry': 'å…¨éƒ¨'
                }
            },
            {
                'name': 'åš´æ ¼æˆäº¤é‡ç¯©é¸',
                'filters': {
                    'price_change_min': -100.0,
                    'price_change_max': 100.0,
                    'volume_ratio_min': 2.0,  # è¦æ±‚æˆäº¤é‡ >= 200%
                    'industry': 'å…¨éƒ¨'
                }
            }
        ]
        
        base_config = {
            'technical': {
                'momentum': {
                    'enabled': True,
                    'rsi': {'enabled': True, 'period': 14},
                    'macd': {'enabled': False},
                    'kd': {'enabled': False}
                },
                'volatility': {
                    'enabled': False,
                    'bollinger': {'enabled': False},
                    'atr': {'enabled': True, 'period': 14}
                },
                'trend': {
                    'enabled': True,
                    'adx': {'enabled': False},
                    'ma': {'enabled': True, 'windows': [5, 10, 20, 60]}
                }
            },
            'patterns': {
                'selected': ['Wåº•']
            },
            'signals': {
                'technical_indicators': ['momentum', 'trend'],
                'volume_conditions': ['increasing'],
                'weights': {'pattern': 0.30, 'technical': 0.50, 'volume': 0.20}
            },
            'regime': current_regime
        }
        
        for filter_test in filter_tests:
            test_name = filter_test['name']
            filters = filter_test['filters']
            
            logger.info(f"\n[Filter Test] {test_name}")
            logger.info(f"  ç¯©é¸æ¢ä»¶: {filters}")
            
            try:
                test_config = {**base_config, 'filters': filters}
                
                recommendations = recommendation_service.run_recommendation(
                    config=test_config,
                    max_stocks=50,
                    top_n=10
                )
                
                logger.info(f"  è¿”å› {len(recommendations)} å€‹æ¨è–¦")
                
                # é©—è­‰ç¯©é¸æ˜¯å¦ç”Ÿæ•ˆ
                if len(recommendations) > 0:
                    df = pd.DataFrame([rec.to_dict() for rec in recommendations])
                    
                    # æª¢æŸ¥æ¼²å¹…ç¯©é¸
                    if filters.get('price_change_min', -100) > -100:
                        if 'æ¼²å¹…%' in df.columns:
                            min_price_change = df['æ¼²å¹…%'].min()
                            if min_price_change < filters['price_change_min']:
                                result.add_fail(
                                    f'{test_name}_PriceFilter',
                                    f"æ¼²å¹…ç¯©é¸æœªç”Ÿæ•ˆ: æœ€å°æ¼²å¹… {min_price_change:.2f}% < è¦æ±‚ {filters['price_change_min']:.2f}%",
                                    evidence={'df_min': min_price_change, 'filter_min': filters['price_change_min']},
                                    issue_type='logic_errors'
                                )
                            else:
                                result.add_pass(f'{test_name}_PriceFilter', {
                                    'min_price_change': min_price_change,
                                    'filter_min': filters['price_change_min']
                                })
                    
                    # æª¢æŸ¥æˆäº¤é‡ç¯©é¸
                    if filters.get('volume_ratio_min', 0) > 0:
                        # volume_ratio_min éœ€è¦è½‰æ›ç‚ºç™¾åˆ†æ¯”è®ŠåŒ–
                        volume_ratio_min_pct = (filters['volume_ratio_min'] - 1) * 100
                        if 'æˆäº¤é‡è®ŠåŒ–ç‡%' in df.columns:
                            min_volume_change = df['æˆäº¤é‡è®ŠåŒ–ç‡%'].min()
                            if min_volume_change < volume_ratio_min_pct:
                                result.add_fail(
                                    f'{test_name}_VolumeFilter',
                                    f"æˆäº¤é‡ç¯©é¸æœªç”Ÿæ•ˆ: æœ€å°è®ŠåŒ–ç‡ {min_volume_change:.2f}% < è¦æ±‚ {volume_ratio_min_pct:.2f}%",
                                    evidence={'df_min': min_volume_change, 'filter_min': volume_ratio_min_pct},
                                    issue_type='logic_errors'
                                )
                            else:
                                result.add_pass(f'{test_name}_VolumeFilter', {
                                    'min_volume_change': min_volume_change,
                                    'filter_min': volume_ratio_min_pct
                                })
                
            except Exception as e:
                result.add_fail(
                    f'{test_name}_Exception',
                    str(e),
                    traceback.format_exc(),
                    issue_type='logic_errors'
                )
        
    except Exception as e:
        logger.error(f"ç¯©é¸é‚è¼¯é©—è­‰å¤±æ•—: {e}")
        logger.error(traceback.format_exc())
        result.add_fail('Filter_Logic_Setup', str(e), traceback.format_exc())


def generate_report(result: ValidationResult) -> str:
    """ç”Ÿæˆ Markdown å ±å‘Š"""
    report_lines = [
        "# Recommendation Analysis Tab é©—è­‰å ±å‘Š",
        "",
        f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        "",
        "## ğŸ“Š æ¸¬è©¦æ‘˜è¦",
        "",
        f"- âœ… **é€šé**: {len(result.passed)} é …",
        f"- âŒ **å¤±æ•—**: {len(result.failed)} é …",
        f"- â­ï¸ **è·³é**: {len(result.skipped)} é …",
        "",
        "## âœ… é€šéé …ç›®",
        ""
    ]
    
    if result.passed:
        for feature in result.passed:
            report_lines.append(f"- {feature}")
            if feature in result.evidence:
                evidence = result.evidence[feature]
                if isinstance(evidence, dict):
                    report_lines.append(f"  - è­‰æ“š: {json.dumps(evidence, ensure_ascii=False, indent=2)}")
    else:
        report_lines.append("ç„¡")
    
    report_lines.extend([
        "",
        "## âŒ å¤±æ•—é …ç›®",
        ""
    ])
    
    if result.failed:
        for fail in result.failed:
            report_lines.append(f"### {fail['feature']}")
            report_lines.append(f"**éŒ¯èª¤**: {fail['error']}")
            report_lines.append(f"**å•é¡Œé¡å‹**: {fail.get('issue_type', 'unknown')}")
            if fail.get('evidence'):
                report_lines.append(f"**è­‰æ“š**:")
                report_lines.append(f"```json")
                report_lines.append(json.dumps(fail['evidence'], ensure_ascii=False, indent=2))
                report_lines.append(f"```")
            report_lines.append("")
    else:
        report_lines.append("ç„¡")
    
    report_lines.extend([
        "",
        "## â­ï¸ è·³éé …ç›®",
        ""
    ])
    
    if result.skipped:
        for skip in result.skipped:
            report_lines.append(f"- **{skip['feature']}**: {skip['reason']}")
    else:
        report_lines.append("ç„¡")
    
    report_lines.extend([
        "",
        "## ğŸ” å•é¡Œåˆ†é¡",
        ""
    ])
    
    for issue_type, issues in result.issues.items():
        if issues:
            report_lines.append(f"### {issue_type}")
            for issue in issues:
                report_lines.append(f"- **{issue['feature']}**: {issue['error']}")
            report_lines.append("")
    
    report_lines.extend([
        "",
        "## ğŸš¨ é˜»æ“‹ Release çš„å•é¡Œ",
        ""
    ])
    
    blockers = []
    for fail in result.failed:
        issue_type = fail.get('issue_type', 'unknown')
        if issue_type in ['contract_violations', 'logic_errors']:
            blockers.append(fail)
    
    if blockers:
        for blocker in blockers:
            report_lines.append(f"- **{blocker['feature']}**: {blocker['error']}")
    else:
        report_lines.append("ç„¡é˜»æ“‹å•é¡Œ")
    
    report_lines.extend([
        "",
        "## ğŸ“ å»ºè­°",
        "",
        "### å¯å…¨è‡ªå‹•é©—è­‰ï¼ˆâœ… QA script å¯ coverï¼‰",
        "- Service å±¤æ¸¬è©¦",
        "- DTO çµæ§‹é©—è­‰",
        "- åˆ†æ•¸ç¯„åœé©—è­‰",
        "- DataFrame å“è³ªé©—è­‰",
        "- ç¯©é¸é‚è¼¯é©—è­‰",
        "",
        "### éœ€å•Ÿå‹• Qt ä½†å¯è‡ªå‹•åŒ–ï¼ˆâš ï¸ pytest-qt / QTestï¼‰",
        "- UI çµ„ä»¶åˆå§‹åŒ–",
        "- ä¿¡è™Ÿ/æ§½é€£æ¥",
        "- è¡¨æ ¼æ¨¡å‹è¨­ç½®",
        "",
        "### å¿…é ˆäººå·¥æª¢æŸ¥ï¼ˆğŸ‘€ ç´”è¦–è¦º/UXï¼‰",
        "- UI å¸ƒå±€",
        "- æŒ‰éˆ•æ¨£å¼",
        "- é€²åº¦æ¢å‹•ç•«",
        "- éŒ¯èª¤è¨Šæ¯é¡¯ç¤º",
        ""
    ])
    
    return "\n".join(report_lines)


def main():
    """ä¸»å‡½æ•¸"""
    logger.info("=" * 80)
    logger.info("Recommendation Analysis Tab QA é©—è­‰")
    logger.info("=" * 80)
    
    result = ValidationResult()
    
    try:
        # åˆå§‹åŒ–é…ç½®
        config = TWStockConfig()
        
        # é©—è­‰ Service å±¤
        validate_service_layer(config, result)
        
        # é©—è­‰ UI â†” Service Contract
        validate_ui_service_contract(result)
        
        # é©—è­‰ç¯©é¸é‚è¼¯
        validate_filtering_logic(config, result)
        
    except Exception as e:
        logger.error(f"é©—è­‰éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        logger.error(traceback.format_exc())
        result.add_fail('Main_Exception', str(e), traceback.format_exc())
    
    # ç”Ÿæˆå ±å‘Š
    report = generate_report(result)
    report_file = log_dir / 'VALIDATION_REPORT.md'
    report_file.write_text(report, encoding='utf-8')
    logger.info(f"\nå ±å‘Šå·²ä¿å­˜è‡³: {report_file}")
    
    # æ§åˆ¶å°æ‘˜è¦ï¼ˆä½¿ç”¨ logging é¿å…ç·¨ç¢¼å•é¡Œï¼‰
    logger.info("\n" + "=" * 80)
    logger.info("é©—è­‰æ‘˜è¦")
    logger.info("=" * 80)
    logger.info(f"é€šé: {len(result.passed)}")
    logger.info(f"å¤±æ•—: {len(result.failed)}")
    logger.info(f"è·³é: {len(result.skipped)}")
    logger.info(f"\nè©³ç´°å ±å‘Š: {report_file}")
    
    # è¿”å›é€€å‡ºç¢¼
    if result.failed:
        return 1
    return 0


if __name__ == '__main__':
    sys.exit(main())

